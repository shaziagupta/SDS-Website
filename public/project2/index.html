<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Shazia Gupta" />
    <meta name="description" content="Describe your website">
    <link rel="shortcut icon" type="image/x-icon" href="../img/favicon.ico">
    <title>Project 2</title>
    <meta name="generator" content="Hugo 0.70.0" />
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="../css/main.css" />
    <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" />
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,400,200bold,400old" />
    
    <!--[if lt IE 9]>
			<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
			<script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
		<![endif]-->

    
  </head>

  <body>
    <div id="wrap">

      
      <nav class="navbar navbar-default">
  <div class="container">
    <div class="navbar-header">
      <a class="navbar-brand" href="../"><i class="fa fa-home"></i></a>
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <div class="navbar-collapse collapse" id="navbar">
      <ul class="nav navbar-nav navbar-right">
      
        
        <li><a href="../blog/">BLOG</a></li>
        
        <li><a href="../projects/">PROJECTS</a></li>
        
        <li><a href="resumefinal.pdf">RESUME</a></li>
        
      
      </ul>
    </div>
  </div>
</nav>

      
      <div class="container">
        <div class="blog-post">
          <h3>
            <strong><a href="../project2/">Project 2</a></strong>
          </h3>
        </div>
        <div class="blog-title">
          <h4>
          January 1, 0001
            &nbsp;&nbsp;
            
          </h4>
        </div>
        <div class="panel panel-default">
          <div class="panel-body">
            <div class="blogpost">
              


<pre class="r"><code>class_diag&lt;-function(probs,truth){

 tab&lt;-table(factor(probs&gt;.5,levels=c(&quot;FALSE&quot;,&quot;TRUE&quot;)),truth)
 acc=sum(diag(tab))/sum(tab)
 sens=tab[2,2]/colSums(tab)[2]
 spec=tab[1,1]/colSums(tab)[1]
 ppv=tab[2,2]/rowSums(tab)[2]
 if(is.numeric(truth)==FALSE &amp; is.logical(truth)==FALSE) truth&lt;-as.numeric(truth)-1
 ord&lt;-order(probs, decreasing=TRUE)
 probs &lt;- probs[ord]; truth &lt;- truth[ord]

 TPR=cumsum(truth)/max(1,sum(truth))
 FPR=cumsum(!truth)/max(1,sum(!truth))

 dup&lt;-c(probs[-1]&gt;=probs[-length(probs)], FALSE)
 TPR&lt;-c(0,TPR[!dup],1); FPR&lt;-c(0,FPR[!dup],1)

 n &lt;- length(TPR)
 auc&lt;- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )
 data.frame(acc,sens,spec,ppv,auc)
}</code></pre>
<p><em>Introduction: For this project, I used the dataset “survey” from the MASS package. I also used this dataset in my last project, so I’m familiar with the different variables and observations. It contains 237 observations and 12 different variables, all results from an undergraduate student questionnaire from the University of Adelaide which asked them about sex, age, height, exercising frequency, smoking habits and pulse rate. The categorical variables I’ll be looking at are mainly exercise, which has three different groups, and smoking frequency, which also has three different groups. The numerical variables I’ll be looking at are pulse, height and age. Lastly, the binary variable is sex, with male and female groups.</em></p>
<pre class="r"><code>#Dataset
library(&quot;MASS&quot;)
survey1 &lt;- na.omit(survey)</code></pre>
<p>MANOVA Test</p>
<pre class="r"><code>library(ggplot2)
manova1 &lt;- manova(cbind(Age, Pulse)~Sex, data = survey1)
summary(manova1)</code></pre>
<pre><code>##            Df    Pillai approx F num Df den Df Pr(&gt;F)
## Sex         1 0.0061588  0.51125      2    165 0.6007
## Residuals 166</code></pre>
<pre class="r"><code>#type 1 error
1-(0.95^7)</code></pre>
<pre><code>## [1] 0.3016627</code></pre>
<pre class="r"><code>#bonferroni correction
0.05/7</code></pre>
<pre><code>## [1] 0.007142857</code></pre>
<pre class="r"><code>#multivariate normality
ggplot(survey1, aes(x=Age, y=Pulse)) + geom_point(alpha = 0.45, color = &quot;green&quot;) + geom_density_2d(h=2) + coord_fixed() + facet_wrap(~Exer) + xlab(&quot;Age (yr)&quot;) + ylab(&quot;Pulse Rate (bpm)&quot;) + ggtitle(&quot;Pulse Rate vs Age According to Exercise Frequency&quot;) + theme(axis.text.y = element_text(angle=45))</code></pre>
<p><img src="../project2_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p><em>Explanation of MANOVA Test: I conducted a one-way multivariate analysis of variance, or MANOVA, to determine if the means for both females and males differed for age and pulse rate in these undergraduate students. My null hypothesis is that the means for both sexes in regards to age and pulse do not differ, and my alternate hypothesis is that the means differ between males and females for age and pulse rate. Looking at the results and the p-value of 0.6007, it is evident that the means for both sexes are equal for Age and Pulse rate, and I cannot reject the null hypothesis. If the p-value turned out to be significant I would have run two ANOVA tests and three post-hoc t tests, one for each exercise group, creating a total of six tests. The probability of a type 1 error is 0.3016627, and with the bonferroni correction it decreases to 0.007142857, meaning there was a difference of 0.29452. The assumptions for the MANOVA test are that the data contains random samples, independent observations and the dependent variables have multivariate normality. By looking at the plot generated above, I can say that these assumptions are not likely to have been met.</em></p>
<p>Randomization Test</p>
<pre class="r"><code>library(dplyr)</code></pre>
<pre><code>## 
## Attaching package: &#39;dplyr&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:MASS&#39;:
## 
##     select</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     filter, lag</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     intersect, setdiff, setequal, union</code></pre>
<pre class="r"><code>#type of test: Welch Two Sample t-test
t.test(data = survey1, Height~Sex)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  Height by Sex
## t = -12.358, df = 147.99, p-value &lt; 2.2e-16
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -15.94564 -11.54912
## sample estimates:
## mean in group Female   mean in group Male 
##             165.6026             179.3500</code></pre>
<pre class="r"><code>diff1 &lt;- vector()
for(i in 1:10000) {
  rand=survey1
  rand$Height=sample(rand$Height)
  diff1[i] &lt;- mean(rand[rand$Sex==&#39;Female&#39;,]$Height)-mean(rand[rand$Sex==&#39;Male&#39;,]$Height)
}
data.frame(diff1) %&gt;% ggplot(aes(diff1)) + geom_histogram(aes(y=..density..), bins = 30) + stat_function(fun = dt, args = list(df=24), geom = &quot;line&quot;) + ggtitle(&quot;Null Distribution of Height&quot;) + scale_y_continuous(breaks = seq(0,0.4,0.05))</code></pre>
<p><img src="../project2_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<pre class="r"><code>quantile(diff1, 0.975)</code></pre>
<pre><code>##    97.5% 
## 3.028833</code></pre>
<pre class="r"><code>qt(0.975, df=24)</code></pre>
<pre><code>## [1] 2.063899</code></pre>
<p><em>Explanation of Randomization Test: I chose to do a two sample t test for the randomization, with the null hypothesis being that the mean of the Heights do not differ across males and females. The alternative hypothesis is that the mean of the Heights do differ between males and females. The t-value is -12.358 and the df is 147.99. The p-value from the test is less than 0.00000000000000022, meaning that there is a significant different between the Heights of males and females. Therefore, I can reject the null hypothesis. The mean Height of males is 179.35 cm, and the mean Height of females is 165.6026 cm. The histogram above displays the null distribution and test statistic.</em></p>
<p>Linear Regression Model</p>
<pre class="r"><code>library(sandwich)
library(lmtest)</code></pre>
<pre><code>## Loading required package: zoo</code></pre>
<pre><code>## 
## Attaching package: &#39;zoo&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     as.Date, as.Date.numeric</code></pre>
<pre class="r"><code>#mean-center numeric variables
height_c &lt;- survey$Height-mean(survey1$Height)
age_c &lt;- survey$Age-mean(survey1$Age)

#regression model
fit &lt;- lm(Height ~ Exer*Age, data = survey1)
summary(fit)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Height ~ Exer * Age, data = survey1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -20.5619  -6.9847  -0.9862   6.5598  24.6806 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  177.8528     3.3366  53.303   &lt;2e-16 ***
## ExerNone     -14.5782     8.9880  -1.622    0.107    
## ExerSome      -7.5966     6.2615  -1.213    0.227    
## Age           -0.1369     0.1522  -0.900    0.370    
## ExerNone:Age   0.4151     0.4009   1.035    0.302    
## ExerSome:Age   0.1251     0.3022   0.414    0.679    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 9.727 on 162 degrees of freedom
## Multiple R-squared:  0.07469,    Adjusted R-squared:  0.04614 
## F-statistic: 2.615 on 5 and 162 DF,  p-value: 0.02645</code></pre>
<pre class="r"><code>ggplot(survey1, aes(x=Age, y=Height, group=Sex)) + geom_point(aes(color=Sex)) + geom_smooth(method = &quot;lm&quot;, formula = y~1, se=F, fullrange=T, aes(color=Sex)) + theme(legend.position = c(0.9, 0.15)) + xlab(&quot;Age (yrs)&quot;) + ylab(&quot;Height (cm)&quot;) + ggtitle(&quot;Height vs Age for each Sex&quot;) + theme(axis.text.y = element_text(angle=45))</code></pre>
<p><img src="../project2_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<pre class="r"><code>#assumptions
resids &lt;- fit$residuals
fitvals &lt;- fit$fitted.values
ggplot() + geom_point(aes(fitvals, resids), color = &quot;darkgreen&quot;) + geom_hline(yintercept = 0, color = &#39;magenta&#39;) + ggtitle(&quot;Assumptions Plot 1&quot;)</code></pre>
<p><img src="../project2_files/figure-html/unnamed-chunk-5-2.png" width="672" /></p>
<pre class="r"><code>ggplot() + geom_histogram(aes(resids), bins = 20, fill = &quot;darkgreen&quot;) + ggtitle(&quot;Assumptions Plot 2&quot;) + scale_y_continuous(breaks = seq(0,20,4))</code></pre>
<p><img src="../project2_files/figure-html/unnamed-chunk-5-3.png" width="672" /></p>
<pre class="r"><code>#robust standard errors
summary(fit)$coef[, 1:2]</code></pre>
<pre><code>##                 Estimate Std. Error
## (Intercept)  177.8527971  3.3366091
## ExerNone     -14.5781996  8.9880156
## ExerSome      -7.5965839  6.2615476
## Age           -0.1369404  0.1521976
## ExerNone:Age   0.4151425  0.4009248
## ExerSome:Age   0.1250937  0.3022070</code></pre>
<pre class="r"><code>coeftest(fit, vcov = vcovHC(fit))[, 1:2]</code></pre>
<pre><code>##                 Estimate Std. Error
## (Intercept)  177.8527971  3.7471872
## ExerNone     -14.5781996 17.1117967
## ExerSome      -7.5965839  6.7202897
## Age           -0.1369404  0.1759690
## ExerNone:Age   0.4151425  0.8536767
## ExerSome:Age   0.1250937  0.3301722</code></pre>
<pre class="r"><code>#proportion of variation
summary(fit)$r.sq</code></pre>
<pre><code>## [1] 0.07469393</code></pre>
<p><em>Explanation of Linear Regression Model: For the coefficient estimates, I can see the intercept estimate is 177.85cm, when both exercise levels and age are held constant. When the student does not exercise, the height estimate decreases by about 14.58cm, and if the student does some exercise, the height estimate decreases by about 7.597cm. When the Exercise and Age variables interact, I see that those students who did not exercise had a height estimate of about 0.415cm greater, and those who did some exercise had a height estimate of about 0.125cm greater. Due to the different sampling method and the outliers being removed, the standard errors change with the coeftest after calculating robust standard errors (all of them increased). Looking at the assumption plots, I can see that all the assumptions have been met. The proportion of variance in the outcome of the overall model is 0.07469393, given by the r squared value.</em></p>
<p>Bootstrapping</p>
<pre class="r"><code>boot_dat &lt;- survey[sample(nrow(survey1), replace = TRUE),]
samp_dist &lt;- replicate(5000, {
  boot_dt &lt;- survey[sample(nrow(survey), replace = TRUE),]
  fit2 &lt;- lm(Height~Exer+Age, data = boot_dt)
  coef(fit2)
})
samp_dist %&gt;% t %&gt;% as.data.frame %&gt;% summarize_all(sd)</code></pre>
<pre><code>##   (Intercept) ExerNone ExerSome        Age
## 1    2.062617 2.367195 1.429383 0.08786608</code></pre>
<p><em>Explanation of Bootstrapping: After computing bootstrapped standard errors, I can see that the standard error for those who did not exercise is 2.328501, the SE for those who did some exercise is 1.405974, and the SE for Age is 0.0889. The intercept SE is 2.048675, which is less than both the original and robust intercept SE’s. These standard errors are smaller than the original standard errors, and also smaller than the robust SE’s.</em></p>
<p>Logistic Regression</p>
<pre class="r"><code>library(tidyverse)</code></pre>
<pre><code>## ── Attaching packages ────────────────────────────────── tidyverse 1.3.0 ──</code></pre>
<pre><code>## ✔ tibble  2.1.3     ✔ purrr   0.3.3
## ✔ tidyr   1.0.2     ✔ stringr 1.4.0
## ✔ readr   1.3.1     ✔ forcats 0.4.0</code></pre>
<pre><code>## ── Conflicts ───────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()
## ✖ dplyr::select() masks MASS::select()</code></pre>
<pre class="r"><code>library(ggplot2)
library(knitr)

fit4 &lt;- glm(Sex~Pulse+Height, data = survey1, family = binomial(link = &quot;logit&quot;))
coeftest(fit4)</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                Estimate  Std. Error z value  Pr(&gt;|z|)    
## (Intercept) -46.0051310   7.0692961 -6.5077 7.629e-11 ***
## Pulse        -0.0066152   0.0183591 -0.3603    0.7186    
## Height        0.2704565   0.0406024  6.6611 2.718e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>exp(coef(fit4))</code></pre>
<pre><code>##  (Intercept)        Pulse       Height 
## 1.047672e-20 9.934066e-01 1.310563e+00</code></pre>
<pre class="r"><code>#confusion matrix
prob &lt;- predict(fit4, type = &quot;response&quot;)
prob</code></pre>
<pre><code>##           1           2           5           6           7           8 
## 0.543699207 0.801238471 0.166402313 0.570708223 0.948186017 0.017412749 
##           9          10          11          14          17          18 
## 0.700244115 0.192435080 0.013532412 0.010761314 0.015793858 0.951034171 
##          20          21          22          23          24          27 
## 0.794077708 0.993571317 0.908270500 0.912585426 0.966062921 0.528156802 
##          28          30          32          33          34          36 
## 0.728085559 0.203997014 0.896697028 0.185810594 0.901497325 0.992931399 
##          38          39          42          44          47          48 
## 0.946691840 0.970690727 0.010182032 0.768742426 0.892962065 0.340158887 
##          49          50          51          52          53          54 
## 0.275807795 0.153089770 0.999557369 0.992837931 0.378756223 0.884538557 
##          55          57          59          61          62          63 
## 0.942021850 0.020298386 0.841827721 0.984228126 0.241935164 0.841983426 
##          65          71          73          74          75          76 
## 0.111685469 0.389146716 0.448457589 0.282840879 0.123256470 0.382875455 
##          77          79          82          85          86          87 
## 0.132094531 0.141535121 0.773413064 0.220772128 0.207238515 0.075662982 
##          88          89          91          93          95          97 
## 0.371995076 0.881808500 0.952223546 0.136711757 0.878317484 0.992837931 
##          98         100         102         104         105         106 
## 0.202452302 0.720156897 0.395454874 0.700244115 0.079443032 0.364301330 
##         109         110         111         112         113         114 
## 0.904966157 0.910989264 0.694660687 0.993224305 0.383436989 0.974229278 
##         115         116         117         118         119         120 
## 0.080421351 0.023292193 0.030306648 0.996511290 0.396854081 0.956783046 
##         122         123         124         125         127         128 
## 0.796232699 0.476214830 0.907772914 0.722815443 0.564213561 0.862326541 
##         129         130         131         132         134         135 
## 0.017412749 0.004106326 0.986087592 0.850586977 0.037115492 0.696942822 
##         136         138         140         141         143         144 
## 0.989183189 0.951646622 0.216067754 0.683321495 0.569086748 0.885134588 
##         145         146         147         148         149         150 
## 0.515882620 0.971617236 0.987949174 0.976932646 0.120425397 0.111685469 
##         151         152         153         154         155         156 
## 0.998036634 0.129090346 0.004513496 0.562586357 0.910451393 0.569812666 
##         158         160         161         163         164         166 
## 0.239516973 0.982269096 0.202924929 0.995468360 0.345064630 0.248940407 
##         167         168         170         172         174         175 
## 0.379754242 0.040829215 0.908270500 0.949152388 0.154813015 0.020563167 
##         176         177         178         180         181         182 
## 0.328382981 0.551160097 0.099218078 0.075662982 0.515882620 0.126940375 
##         183         184         185         186         187         188 
## 0.070531614 0.379754242 0.674670800 0.260237443 0.079928161 0.140662544 
##         189         190         191         192         193         194 
## 0.592352592 0.998624530 0.861168413 0.907217587 0.758665641 0.039053826 
##         196         197         198         199         200         201 
## 0.132094531 0.375648149 0.010248918 0.364301330 0.101608184 0.224014288 
##         202         204         205         206         207         208 
## 0.676288813 0.035536925 0.870389916 0.246474963 0.006740790 0.035993180 
##         209         211         212         214         215         218 
## 0.116965645 0.038360290 0.078003750 0.140662544 0.315428030 0.969147005 
##         220         222         223         227         228         229 
## 0.987188899 0.244369925 0.067744666 0.375648149 0.972866722 0.213835181 
##         230         231         233         234         236         237 
## 0.972337913 0.304237484 0.128413902 0.035086243 0.947501263 0.269826316</code></pre>
<pre class="r"><code>class_diag(prob, survey1$Sex)</code></pre>
<pre><code>##            acc      sens      spec       ppv       auc
## Male 0.8511905 0.8333333 0.8690476 0.8641975 0.9099348</code></pre>
<pre class="r"><code>table(predict = as.numeric(prob&gt;0.5), truth = survey1$Sex) %&gt;% addmargins</code></pre>
<pre><code>##        truth
## predict Female Male Sum
##     0       73   14  87
##     1       11   70  81
##     Sum     84   84 168</code></pre>
<pre class="r"><code>#ROC
library(plotROC)
ROCplot &lt;- ggplot(survey1) + geom_roc(aes(d=Sex, m=prob), n.cuts = 0) + ggtitle(&quot;ROC Curve&quot;) + theme(axis.text.y = element_text(angle=45))
ROCplot</code></pre>
<pre><code>## Warning in verify_d(data$d): D not labeled 0/1, assuming Female = 0 and Male =
## 1!</code></pre>
<p><img src="../project2_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<pre class="r"><code>calc_auc(ROCplot)</code></pre>
<pre><code>## Warning in verify_d(data$d): D not labeled 0/1, assuming Female = 0 and Male =
## 1!</code></pre>
<pre><code>##   PANEL group       AUC
## 1     1    -1 0.9099348</code></pre>
<pre class="r"><code>prob &lt;- predict(fit4, type = &quot;response&quot;)
class_diag &lt;- function(probs, truth){
  tab &lt;- table(factor(probs&gt;0.5, levels = c(&quot;FALSE&quot;, &quot;TRUE&quot;)), truth)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]
  
  if(is.numeric(truth)==FALSE &amp; is.logical(truth)==FALSE) truth &lt;- as.numeric(truth)-1
  
  ord &lt;- order(probs, decreasing = TRUE)
  probs &lt;- probs[ord]; truth &lt;- truth[ord]
  
  TPR = cumsum(truth)/max(1, sum(truth))
  FPR = cumsum(!truth)/max(1, sum(!truth))
  
  dup &lt;- c(probs[-1]&gt;=probs[-length(probs)], FALSE)
  TPR &lt;- c(0, TPR[!dup], 1); FPR &lt;- c(0, FPR[!dup], 1)
  
  n &lt;- length(TPR)
  auc &lt;- sum( ((TPR[-1] + TPR[-n])/2) * (FPR[-1]-FPR[-n]) )
  
  data.frame(acc, sens, spec, ppv, auc)
}

class_diag(prob, survey1$Sex)</code></pre>
<pre><code>##            acc      sens      spec       ppv       auc
## Male 0.8511905 0.8333333 0.8690476 0.8641975 0.9099348</code></pre>
<pre class="r"><code>#Density Plot
odds &lt;- function(p)p/(1-p)
p &lt;- seq(0,1, by=0.1)
logit &lt;- function(p)log(odds(p))
cbind(p, odds = odds(p), logit=logit(p)) %&gt;% round(4)</code></pre>
<pre><code>##         p   odds   logit
##  [1,] 0.0 0.0000    -Inf
##  [2,] 0.1 0.1111 -2.1972
##  [3,] 0.2 0.2500 -1.3863
##  [4,] 0.3 0.4286 -0.8473
##  [5,] 0.4 0.6667 -0.4055
##  [6,] 0.5 1.0000  0.0000
##  [7,] 0.6 1.5000  0.4055
##  [8,] 0.7 2.3333  0.8473
##  [9,] 0.8 4.0000  1.3863
## [10,] 0.9 9.0000  2.1972
## [11,] 1.0    Inf     Inf</code></pre>
<pre class="r"><code>survey1$logit &lt;- predict(fit4)
survey1$outcome &lt;- factor(survey1$Sex, levels = c(&quot;Male&quot;, &quot;Female&quot;))
ggplot(survey1, aes(logit, fill=as.factor(Sex))) + geom_density(alpha = 0.35) + geom_vline(xintercept = 0, lty=2) + ggtitle(&quot;Density of Log Odds by Sex&quot;) + theme(legend.position = c(0.9, 0.65))</code></pre>
<p><img src="../project2_files/figure-html/unnamed-chunk-7-2.png" width="672" /></p>
<pre class="r"><code>#10-fold CV
set.seed(1234)
k=10
data1 &lt;- survey[sample(nrow(survey)), ]
folds &lt;- cut(seq(1:nrow(survey)), breaks = k, labels = F)
diags &lt;- NULL
for (i in 1:k) {
  train &lt;- data1[folds !=i, ]
  test &lt;- data1[folds == i, ]
  truth &lt;- test$Sex
  fit5 &lt;- glm(Sex ~ Age+Height, data = survey, family = &quot;binomial&quot;)
  probs &lt;- predict(fit5, newdata = test, type = &quot;response&quot;)
  preds &lt;- ifelse(probs &gt; 0.5, 1, 0)
  diags &lt;- rbind(diags, class_diag(probs, truth))
}
diags %&gt;% summarize_all(mean)</code></pre>
<pre><code>##         acc      sens      spec       ppv auc
## 1 0.8197737 0.7847283 0.8518254 0.8434722  NA</code></pre>
<pre class="r"><code>summary(fit5)</code></pre>
<pre><code>## 
## Call:
## glm(formula = Sex ~ Age + Height, family = &quot;binomial&quot;, data = survey)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -2.12336  -0.70895   0.06886   0.49056   2.92596  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -43.59588    6.00072  -7.265 3.73e-13 ***
## Age           0.01453    0.02427   0.599    0.549    
## Height        0.25223    0.03470   7.268 3.65e-13 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 288.27  on 207  degrees of freedom
## Residual deviance: 166.67  on 205  degrees of freedom
##   (29 observations deleted due to missingness)
## AIC: 172.67
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p><em>Explanation of Logistic Regression: For this part of the project, my null hypothesis is that when controlling for Pulse Rate, the students’ Height does not explain the variation between the two sexes, and when controlling for Height, the Pulse Rate does not explain the variation in sex. From the results of the logistic regression, I can see that Height does explain variation with a coefficient estimate of 0.270465, while Pulse Rate does not explain variation between sexes with a coefficient estimate of -0.0066152. The Accuracy is 0.8511905, which provides the proportion of classified cases, and the Sensitivity is 0.833, which is the true positive rate. The Specificity is 0.8690476, which is the true negative rate, and the PPV is 0.8641975, and is the positive predicted value. The AUC is 0.9099348, which explains why the ROC plot above is not a perfect curve. After performing the 10-fold CV, I found that the average out of sample Accuracy is 0.8197737, the Sensitivity is 0.7847283, the Specificity is 0.8518254 and the PPV is 0.8434722.</em></p>
<p>LASSO Regression</p>
<pre class="r"><code>library(glmnet)</code></pre>
<pre><code>## Loading required package: Matrix</code></pre>
<pre><code>## 
## Attaching package: &#39;Matrix&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:tidyr&#39;:
## 
##     expand, pack, unpack</code></pre>
<pre><code>## Loading required package: foreach</code></pre>
<pre><code>## 
## Attaching package: &#39;foreach&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:purrr&#39;:
## 
##     accumulate, when</code></pre>
<pre><code>## Loaded glmnet 2.0-16</code></pre>
<pre class="r"><code>#LASSO
y &lt;- as.matrix(survey1$Wr.Hnd)
x &lt;- survey1 %&gt;% dplyr::select(Age, NW.Hnd, Height, Pulse) %&gt;% mutate_all(scale) %&gt;% as.matrix
cv &lt;- cv.glmnet(x,y)
lasso1 &lt;- glmnet(x,y, lambda = cv$lambda.1se)
coef(lasso1)</code></pre>
<pre><code>## 5 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                      s0
## (Intercept) 18.80238095
## Age          .         
## NW.Hnd       1.68162642
## Height       0.05373305
## Pulse        .</code></pre>
<pre class="r"><code>#10-fold CV
set.seed(1234)
k=10
data2 &lt;- survey1[sample(nrow(survey1)), ]
folds &lt;- cut(seq(1:nrow(survey1)), breaks = k, labels = F)
diags &lt;- NULL
for(i in 1:k) {
  train &lt;- data2[folds!=i, ]
  test &lt;- data2[folds==i, ]
  fit5 &lt;- lm(Wr.Hnd~NW.Hnd+Height, data = survey1)
  yhat &lt;- predict(fit, newdata = test)
  diags &lt;- mean((test$Wr.Hnd-yhat)^2)
}
mean(diags)</code></pre>
<pre><code>## [1] 23449.72</code></pre>
<pre class="r"><code>summary(fit5)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Wr.Hnd ~ NW.Hnd + Height, data = survey1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.72985 -0.30745  0.03575  0.32655  1.34788 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.312238   0.666572  -0.468  0.64010    
## NW.Hnd       0.893038   0.024880  35.893  &lt; 2e-16 ***
## Height       0.013837   0.004939   2.802  0.00569 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.4938 on 165 degrees of freedom
## Multiple R-squared:  0.9346, Adjusted R-squared:  0.9338 
## F-statistic:  1179 on 2 and 165 DF,  p-value: &lt; 2.2e-16</code></pre>
<p><em>Explanation of LASSO: For this last part of the project, I chose the Age, NW.Hnd (span of non-writing hand), Height and Pulse variables to see if they had any effect on the Wr.Hnd (span of writing hand). From the results, I can see that the Height and NW.Hnd variables have been retained, while Pulse and Age have not. This means that Height and NW.Hnd have an effect on the WR.Hnd. After performing the 10-fold CV I found the residual standard error to be 0.4938, which is a smaller value than the residual standard error found in the logistic regression (0.8197737) and indicates a better fit.</em></p>

              <hr>
              <div class="related-posts">
                <h5>Related Posts</h5>
                
              </div>
            </div>
          </div>
          <hr>
        <div class="disqus">
  <div id="disqus_thread"></div>
  <script type="text/javascript">

    (function() {
      
      
      if (window.location.hostname == "localhost")
        return;

      var disqus_shortname = '';
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div>
        </div>
      </div>
      
    </div>

    
    <footer>
  <div id="footer">
    <div class="container">
      <p class="text-muted">&copy; All rights reserved. Powered by <a href="https://gohugo.io/">Hugo</a> and
      <a href="http://www.github.com/nurlansu/hugo-sustain/">sustain</a> with ♥</p>
    </div>
  </div>
</footer>
<div class="footer"></div>


<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<script src="../js/docs.min.js"></script>
<script src="../js/main.js"></script>

<script src="../js/ie10-viewport-bug-workaround.js"></script>


    
  </body>
</html>
